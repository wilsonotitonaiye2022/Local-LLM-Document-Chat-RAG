# Local-LLM-Document-Chat-RAG
This is a streamlit app developed for local LLM interaction

This app was implemented uses :100:% open-source Large language Models (LLMs). It uses locally installed LLM models on the Ollama framework. 
A couple of models was used in the implementation of this app;[BGE-M3](https://ollama.com/library/bge-m3) was used for embedding the document while 
[GEMMA 3 12B](https://ollama.com/library/gemma3) was used for retrival of responses.

You will need to install [Ollama](https://ollama.com/download) to download model be you can run the app.
